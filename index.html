<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- DELETE THIS SCRIPT if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script-->

  <title>Purva Tendulkar</title>

  <meta name="author" content="Purva Tendulkar">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Purva Tendulkar</name><br>
                purva at gatech dot edu
              </p>
              <p> I am a second year computer science MS
              student at Georgia Tech, advised by <a href="https://www.cc.gatech.edu/~parikh/">Prof. Devi Parikh</a>. I also collaborate with <a href="https://anikem.github.io/">Ani Kembhavi</a> at AI2. I earned my Bachelors in Computer Engineering in 2018 from College of Engineering Pune, India.
              </p>

              <p class="content">In the past couple of years, I have had the fortune to intern / conduct research at <a href="http://aibee.com/en/">AiBee Inc., Palo Alto</a> (Summer 2019) mentored by <a href="https://scholar.google.com/citations?user=Te3H6mMAAAAJ&hl=en">Chunhui Gu</a> and <a href="http://www.niebles.net/">Juan Carlos Niebles</a> and; <a href="https://cps-research-group.github.io/">Cyber-Physical Systems Research Group, NTU Singapore</a> (Summer 2017) mentored by <a href="https://www.ntu.edu.sg/home/arvinde/">Arvind Easwaran</a> and <a href="http://research.ntu.edu.sg/expertise/academicprofile/Pages/StaffProfile.aspx?ST_EMAILID=ANUPAM&">Anupam Chattopadhyay</a>, on a diverse set of topics - ranging from vision & language to cyber security.</p>

              <p class="content">In my free time, I play the Harmonium instrument. I am very passionate about music. I love to learn about different music styles and their histories. I am also a trained Bharatnatyam dancer.</p>

              <p style="text-align:center">
                <a href="mailto:purva@gatech.edu"> Email </a> &nbsp/&nbsp
                <a href="data/Purva_Tendulkar_Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=-7JsjAsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/purva-tendulkar-774b48151/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://github.com/purvaten"> Github </a> &nbsp/&nbsp
                <a href="https://twitter.com/PurvaTendulkar"> Twitter </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/purva.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/purva-circ.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in the broad areas of Machine Learning, Computer Vision & Language and Reinforcement Learning. My primary research interest is in connecting humans and AI, i.e., developing personable AI that humans can like, trust, teach and learn from. My work so far has attempted to address tasks along these lines to make AI:
              </p>
              <p class="content">
              <ul>
                <li><b><i>creative, </i></b> so that they may assist humans and spur human creativity</li>
                <li><b><i>trustworthy, </i></b> so that predictions made by such systems can be explained, trusted and more reliably deployed</li>
                <li><b><i>learn to learn like humans do, </i></b> so that they can give insight into how humans learn and made more immersive</li>
              </ul>
              </p>
              <!-- <p>
                Representative papers are <span class="highlight">listed under Publications</span>.
              </p> -->

            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
              <ul>
                <li><strong>[Jun 2020]</strong> Our work on dance generation was covered by Engadget in <a href="https://www.engadget.com/facebook-ai-choreography-170023727.html">this blogpost</a>.</li>
                <li><strong>[May 2020]</strong> New <a href="https://arxiv.org/abs/2006.11905">preprint</a> on dance generation given music available.</li>
                <li><strong>[Feb 2020]</strong> Our <a href="https://arxiv.org/abs/2001.06927">paper</a> is accepted as an Oral at CVPR 2020!</li>
                <li><strong>[Jan 2020]</strong> New <a href="https://arxiv.org/abs/2001.06927">preprint</a> on reasoning in VQA models available.</li>
                <li><strong>[Jun 2019]</strong> I was awarded the Best Presentation Award at ICCC 2019!</li>
                <li><strong>[Jun 2019]</strong> Presented our work on creating doodles or "TReATs" at the <a href="http://www.computationalcreativity.net/iccc2019/"> Tenth International Conference on Computational Creativity, ICCC 2019</a>.</li>
                <li><strong>[May 2019]</strong> I will be interning at <a href="http://aibee.com/en">AiBee Inc.</a> at Palo Alto in summer 2019.</li>
                <li><strong>[Jul 2018]</strong> I will be joining Georgia Tech as a Masters of Computer Science student in Fall 2018.</li>
                <li><strong>[Jul 2018]</strong> Code for NAACL 2018 paper <a href="https://arxiv.org/abs/1704.08224">Punny Captions: Witty Wordplay in Image Descriptions</a> now available on <a href="https://github.com/purvaten/punny_captions">GitHub</a>.</li>
                <li><strong>[May 2018]</strong> Code for ICCP 2016 paper <a href="https://ieeexplore.ieee.org/document/7492870">Blind dehazing using internal patch recurrence</a> now available on <a href="https://github.com/purvaten/blind-dehazing">GitHub</a>.</li>
              </ul>
            </td>
          </tr>
        </table>

        <!--table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Achievements</heading>
              <ul>
                <li>Recognized as an <a href="https://iclr.cc/Conferences/2019/Awards">outstanding reviewer</a> for ICLR 2019!</li>
                <li>Recognized to be among the top 20 percent highest scoring reviewers for NeurIPS 2018!</li>
                <li>Awarded the College of Computing's MS Research Award at Georgia Tech!</li>
                <li>Our team won <a href="http://www.vthacks.com/">VT Hacks 2017</a>, a <a href="https://mlh.io/"> Major League Hacking Event</a>, 2017!</li>
                <li>Our undergraduate team, DTU-AUV, qualified for the semi-finals at <a href="http://www.auvsifoundation.org/2014-robosub-teams">AUVSI Robosub 2014</a>!</li>
                <li>Awarded Merit Scholarships from 2012-2014 for undergraduate academic performance!</li>
                <li>Selected for <a href="http://kvpy.iisc.ernet.in/main/index.htm">KVPY</a> and <a href="http://www.inspire-dst.gov.in/fellowship.html">INSPIRE</a> Fellowships, 2012 for undergraduate studies in basic sciences!</li>
                <li>Placed among the top 1 percent students in the country in <a href="http://www.indapt.org/index.php/inphoipho">INPhO</a> 2012!</li>
                <li>Selected for rigorous mathematical training camps conducted by mathematicians from Bhabha Atomic Research Center (<a href="http://www.barc.gov.in/">BARC</a>) and Indian Institute of Science (<a href="http://www.iisc.ac.in/">IISc</a>) in 2012!</li>
                <li>Selected for <a href="http://www.csirhrdg.res.in/cpyls.htm">CSIR Programme on Youth Leadership in Science</a>, 2010!</li>

              </ul>
            </td>
          </tr>
        </table-->

        <!-- PAPERS -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Papers</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:105%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- <heading>Publications</heading> -->

            <!--sort-->
            <!-- <tr>
              <td width="35%"><img src="images/sort_teaser.png" alt="3DSP" width="300" style="padding: 20px">
              <td valign="top" width="70%">
                <a>
                        <papertitle>SOrT-ing VQA Models: Improving Consistency via Gradient Alignment</papertitle>
                </a>
              <br>
              Sameer Dharur,
              <strong>Purva Tendulkar</strong>,
              Dhruv Batra,
              Devi Parikh,
              Ramprasaath Selvaraju
              <br>
                <strong>Keywords: </strong> visual question answering, relevant sub-questions, consistency<br>
                <em>Pre-print</em> (under review) <br>
                [Contact for paper]
              </td>
            </tr> -->

            <!--dancing agents-->
            <tr>
              <td width="35%"><img src="images/dancing_teaser.png" alt="3DSP" width="300" style="padding: 20px">
              <td valign="top" width="70%">
                <a href="https://arxiv.org/abs/2006.11905">
                        <papertitle>Feel The Music: Automatically Generating A Dance For An Input Song</papertitle>
                </a>
              <br>
              <strong>Purva Tendulkar</strong>,
              Abhishek Das,
              Ani Kembhavi,
              Devi Parikh
              <br>
                <strong>Keywords: </strong> dance, creativity, music, human studies<br>
                <em>Pre-print</em> (under review)<br>
                <a href="data/dancing_agents_paper.pdf">paper</a> /
                <a href="https://youtu.be/kkIzhFV9YFE?t=1362">video</a> /
                <a href="https://sites.google.com/view/dancing-agents">website</a> /
                <a href="https://www.engadget.com/facebook-ai-choreography-170023727.html">press coverage</a>
              </td>
            </tr>

            <!--squint-->
            <tr>
            <td width="35%"><img src="images/squint_teaser.jpg" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a href="https://arxiv.org/abs/2001.06927">
                      <papertitle>SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions</papertitle>
              </a>
            <br>
            Ramprasaath R. Selvaraju,
            <strong>Purva Tendulkar</strong>,
            Devi Parikh,
            Eric Horvitz,
            Marco Ribeiro,
            Besmira Nushi,
            Ece Kamar
            <br>
              <strong>Keywords: </strong> visual question answering, consistency, sub-questions, reasoning<br>
              <em>CVPR</em>, 2020 <em><span class="cool">(Oral)</span></em><br>
              <a href="data/squint_paper.pdf">paper</a> /
              <a href="http://y2u.be/v3HhAfj7WpU">video</a> /
              <a href="https://www.microsoft.com/en-us/research/project/vqa-introspect/">data</a>
            </td>
            </tr>

            <!--treat-->
            <tr>
            <td width="35%"><img src="images/TREAT_teaser.png" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a href="https://arxiv.org/abs/1903.07820">
                      <papertitle>Trick or TReAT: Thematic Reinforcement for Artistic Typography</papertitle>
              </a>
            <br>
            <strong>Purva Tendulkar</strong>,
            Kalpesh Krishna,
            Ramprasaath R. Selvaraju,
            Devi Parikh
            <br>
              <strong>Keywords: </strong> computer vision, unsupervised learning, creativity<br>
              <em>ICCC</em>, 2019 <em><span class="cool">(Oral, Best Presentation Award)</span></em><br>
              <a href="data/treat_paper.pdf">paper</a> /
              <a href="https://www.youtube.com/watch?v=c9MvbeQkZwQ">video</a> /
              <a href="data/TReAT-talk.pdf">slides pdf</a> /
              <a href="https://tinyurl.com/ybkvsojr">google slides</a> /
              <a href="http://doodle.cloudcv.org/">demo</a> /
              <a href="https://github.com/purvaten/treat">code</a>
            </td>
            </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:105%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- <heading>Publications</heading> -->

          <!--aibee-->
          <tr>
            <td width="35%"><img src="images/aibee_teaser.jpg" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a>
                      <papertitle>Trajectory-based event detection</papertitle>
              </a>
            <br>
            <strong>Purva Tendulkar</strong>,
            Chunhui Gu,
            Juan Carlos Niebles,
            Sinisa Todorovic,
            Silvio Savarese
            <br>
              <strong>Keywords: </strong> deep recurrent neural networks, human trajectories, classification<br>
              <a href="data/aibee.pdf">slides</a>
            </td>
          </tr>

          <!--blind dehazing-->
          <tr>
            <td width="35%"><img src="images/dehazing_teaser.png" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a>
                      <papertitle>Blind image dehazing using internal patch recurrence</papertitle>
              </a>
            <br>
            <strong>Purva Tendulkar</strong>,
            Kalpesh Krishna,
            Yuval Bahat
            <br>
              <strong>Keywords: </strong> computer vision, dehazing<br>
              <a href="data/btech_thesis.pdf">report</a>
            </td>
          </tr>

          <!--cps security-->
          <tr>
            <td width="35%"><img src="images/stuxnet_teaser.jpg" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a>
                      <papertitle>Safety and Security Analysis in Cyber-Physical Systems using Metro-II</papertitle>
              </a>
            <br>
            <strong>Keywords: </strong> cyber security, stuxnet, metropolis<br>
            <strong>Purva Tendulkar</strong>,
            Anupam Chattopadhyay,
            Arvind Easwaran
            <br>
              <a href="data/cps_security_report.pdf">report</a>
            </td>
          </tr>

          <!--evalpro-->
          <tr>
            <td width="35%"><img src="images/evalpro_teaser.jpg" alt="3DSP" width="300" style="padding: 20px">
            <td valign="top" width="70%">
              <a>
                      <papertitle>EvalPro: A project of BodhiTree</papertitle>
              </a>
            <br>
            <strong>Purva Tendulkar</strong>,
            Varsha Apte
            <br>
              <strong>Keywords: </strong> django, html, css, javascript<br>
              <a href="https://bodhitree.cse.iitb.ac.in/">website</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
                  <hr>
                  <p align="center">
                  <font>(Design and CSS courtesy: <a href="https://jonbarron.info/">Jon Barron</a> and <a href="https://abhoi.github.io/">Amlaan Bhoi</a>)</font>
                  </p>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>