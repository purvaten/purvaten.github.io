<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v7.0.0 <https://qwtel.com/hydejack/>
-->












<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="x-ua-compatible" content="ie=edge">


  
<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Research | Purva Tendulkar</title>
<meta property="og:title" content="Research" />
<meta name="author" content="Purva Tendulkar" />
<meta property="og:locale" content="en" />
<meta name="description" content="MS CS Student at Georgia Tech" />
<meta property="og:description" content="MS CS Student at Georgia Tech" />
<link rel="canonical" href="http://localhost:4000/about/" />
<meta property="og:url" content="http://localhost:4000/about/" />
<meta property="og:site_name" content="Purva Tendulkar" />
<script type="application/ld+json">
{"name":"Purva Tendulkar","description":"MS CS Student at Georgia Tech","author":{"@type":"Person","name":"Purva Tendulkar"},"@type":"WebSite","url":"http://localhost:4000/about/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/icons/icon.png"},"name":"Purva Tendulkar"},"image":null,"headline":"Research","dateModified":null,"datePublished":null,"sameAs":null,"mainEntityOfPage":null,"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  

  
    <meta name="keywords" content="">
  


<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Purva Tendulkar">
<meta name="apple-mobile-web-app-status-bar-style" content="black">

<meta name="application-name" content="Purva Tendulkar">
<meta name="msapplication-config" content="/assets/ieconfig.xml">



<meta name="generator" content="Hydejack v7.0.0" />


<link rel="alternate" type="application/atom+xml" title="Purva Tendulkar Feed" href="http://localhost:4000/feed.xml">


<link rel="alternate" href="http://localhost:4000/about/" hreflang="en">

<link rel="shortcut icon" href="/assets/icons/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon.png">

<link rel="manifest" href="/assets/manifest.json">


  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">


  <link rel="dns-prefetch" href="https://www.google-analytics.com">



<link id="_katexJS"  rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.js">
<link id="_katexCSS" rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.css">

<script>
  function stdOnEnd(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function ieOnEnd(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}window.setRelStylesheet=function(n){function e(){this.rel="stylesheet"}var o=document.getElementById(n);o.addEventListener?o.addEventListener("load",e,!1):o.onload=e},window._loaded=!1,window.loadJSDeferred=function(n,e){function o(){window._loaded=!0;var o=document.createElement("script");o.src=n,e&&(("onload"in o?stdOnEnd:ieOnEnd)(o,e),o.onload||stdOnEnd(o,e));var t=document.scripts[0];t.parentNode.insertBefore(o,t)}window._loaded?o():window.addEventListener?window.addEventListener("load",o,!1):window.onload=o};
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);

  window._noPushState = false;
  window._noDrawer = false;
</script>

<!--[if gt IE 8]><!---->


<script>
  WebFontConfig = {
    
    google: {
      families: ['Roboto+Slab:700','Noto+Sans:400,400i,700,700i']
    },
    

    custom: {
      families: ['icomoon'],
      urls: ['/assets/icomoon/style.css']
    }
  };
  (function(d) {
    var wf = d.createElement('script'), s = d.scripts[0];
    wf.src = "/assets/bower_components/webfontloader/webfontloader.js";
    s.parentNode.insertBefore(wf, s);
  }(document));
</script>
<!--<![endif]-->

<noscript>
  
  

  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i">
    <style>
      html { font-family: 'Noto Sans', Helvetica, Arial, sans-serif }
      h1, h2, h3, h4, h5, h6, .h1, .h2, .h3, .h4, .h5, .h6, .heading { font-family: 'Roboto Slab', Helvetica, Arial, sans-serif }
    </style>
  

  <link rel="stylesheet" href="/assets/icomoon/style.css">
</noscript>

<!--[if gt IE 8]><!---->



  <link rel="stylesheet" href="/assets/css/hydejack.css?v=7.0.0">



<style id="_pageStyle">

.content a:not(.btn){color:#4fb1ba;border-color:rgba(79,177,186,0.2)}.content a:not(.btn):hover{border-color:#4fb1ba}:focus{outline-color:#4fb1ba}.btn-primary{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:focus,.btn-primary.focus{box-shadow:0 0 0 3px rgba(79,177,186,0.5)}.btn-primary:hover,.btn-primary.hover{color:#fff;background-color:#409ba3;border-color:#409ba3}.btn-primary:disabled,.btn-primary.disabled{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:active,.btn-primary.active{color:#fff;background-color:#409ba3;border-color:#409ba3}::selection{color:#fff;background:#4fb1ba}::-moz-selection{color:#fff;background:#4fb1ba}

</style>

<!--<![endif]-->




</head>

<body>
  <div class="navbar fixed-top">
  <div class="content">
    <div class="nav-btn-bar">
      <span class="sr-only">Jump to:</span>
      <a id="_menu" class="nav-btn no-hover" href="#_navigation">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
    </div>
  </div>
</div>


<hy-push-state>
  <main
    id="_main"
    class="content fade-in layout-about"
    role="main"
    data-color="#4fb1ba"
    
      data-image="assets/img/sidebar-bg.jpg"
      data-overlay
    
    >
    

<article class="page" role="article">
  

  
    
  

  

  <img
    src="assets/img/me.jpg"
    class="avatar"
    alt="Purva Tendulkar"
    
    
    
  />


  

  <h1 class="page-title hr">Research</h1>

  


  



  



  <html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <meta charset="utf-8" />
  <title>Deep Learning Class Project
  | Georgia Tech | Fall 2018: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="" />
  <meta name="author" content="" />

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet" />
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}

* {
    box-sizing: border-box;
}

.column {
    float: left;
    width: 33.33%;
    padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
    content: "";
    clear: both;
    display: table;
}

</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet" />
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Theme-based Word Doodling</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Purva Tendulkar</strong></span><br />
<span style="font-size: 18px; line-height: 1.5em;">Fall 2018 CS 4803 / 7643 Deep Learning: Class Project</span><br />
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr />

<!-- Goal -->
<h2>Abstract</h2>

Recently, there has been a lot of work in using generative models for drawing images. This has many applications, from assisting the creative process of an artist to aiding designers in product design and even advertising. On these lines, word doodling or creative lettering seems like an interesting next step, given its numerous applications in fields like advertising, marketing and logo design. In this project we propose a model to automatically generate a word doodle for any input word, given a theme. Our dataset consists of theme-based cliparts obtained from the <a href="https://thenounproject.com/">Noun Project</a>. We use an auto-encoder based approach for learning a joint representation of cliparts and letter fonts, and propose a <a href="https://arxiv.org/abs/1611.07004">pix2pix</a> approach for generating theme-related objects which resemble natural fonts. Our work shows promising results, and attempts to encourage the community towards using generative models for creative AI tasks.
<br /><br />
<!-- figure -->
<h2>AlexNet-based autoencoder setup</h2>
The <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a> framework shown in the figure is used in the autoencoder setup.
<br /><br />
<!-- Main Illustrative Figure -->
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="../assets/img/autoencoder1.png" />
<img style="height: 200px;" alt="" src="../assets/img/alexnet.png" />
</div>

<br /><br />
<!-- Introduction -->
<h2>Introduction / Background / Motivation</h2>
<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.</h4>
The problem relates to creating a word doodle. A word doodle is basically stylizing a word by modifying its individual letters or groups of letters using cliparts, that is, the individual character(s) are embedded into the clipart such that the resulting (character + image) combination can be discerned as either or both. This can be considered as an artistic way of describing a word, which may convey deeper shades of meaning to the word based on the cliparts used to describe it. An example is shown in the figure below where the input word is "Always" and the theme is "Harry Potter". The specific objectives of the problem can be defined in the following steps-
<ul>
<li>Identify and extract a dataset for theme-based cliparts</li>
<li>Create a model to identify the best theme-related clipart which most closely resmebles a letter of the input word</li>
<li>Generate new theme-related cliparts which are more identifiable as letters of the input word</li>
</ul>
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="../assets/img/io.png" />
</div>

<h4>How is it done today, and what are the limits of current practice?</h4>
<p>This is a unique, creative AI task which has not been explored before. There has been independent work on finding matching regions in images, as well as generating new images.</p>

<p>For find closest matching images (content-wise similarity), there exist algorithms like <a href="https://www.ijcai.org/Proceedings/77-2/Papers/024.pdf">Chamfer Matching</a> or Pattern Matching in OpenCV. However, these do not fit well for our application. Chamfer matching looks for exact matches and is not well supported today, while pattern matching is not scale and tilt invariant and checks pixel-wise similarity through a sliding window. For this application, we are more interested in identifying the common visual features between 2 images (clipart and font), and possibly learning a representation for this to compare different features. We thus use an autoencoder-based approach for this task for the first time.</p>

<p>With respect to image generation, work includes style transfer, pix2pix and recent work on transferring font styles like <a href="https://arxiv.org/abs/1712.00516">Glyphnet</a>. We explore each of these techniques for our application.</p>

<h4>Who cares? If you are successful, what difference will it make?</h4>
This problem is particularly exciting for applications such as advertising, marketing (for generating catchy slogans) and product design. Coming up with visually creative ways to express a message is challenging and non-trivial, as there may be several different interpretations of art, and ways to represent such content. There also does not exist any general evaluation criteria or metric to assess the quality of generated art.
In today's day and age, where AI is advancing rapidly, researchers are struggling to make AI more human-like in its interactions and artistic abilities. This project takes one step towards reaching this goal.

<br /><br />
<!-- Approach -->
<h2>Approach</h2>
<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?</h4>
<p>My contributions were as follows-
<ul>
<li>Developing an AlexNet based autoencoder approach for finding best matches.</li>
<li>Ideas on extending the model using pix2pix or Glyphnet.</li>
</ul>
</p>

<p>I expected that autoencoder-based approach would be able to learn primary features that make an alphabet distinguishable, as also identifying similar key features in cliparts (obtained from the Noun Project). We thus expected this to be sucessful in learning a good representation of both, the cliparts and alphabets. We then used the lower dimensional learnt representations for computing the similarities between letters and cliparts using cosine distance.</p>

<p>For generative models, we were simply interested in visualizing the results to assess the capabilities of current state-of-the-art generative models.</p>

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?</h4>
<p>We had anticipated that there would be problems with data collection and model evaluation, which we did in fact encounter. The data collection for cliparts from Noun Project was pretty straightforward since it simply involved writing some basic <a href="https://github.com/purvaten/doodling">code</a> to scrape the website. However for collecting alphabrts of various fonts, we had to search for several unique font files and manually sift through the data to make sure the letters would be discerned well.</p>

<p>In terms of model evaluation, we planned to use some standard techniques like Chamfer matching and contour matching as a baseline, but had to struggle a lot to find a well-documented code base. These older techniques seem to have become obsolete, and this search took up a lot of time. This was one of the first few things we tried which did not work. However, moving on to use on autoencoder worked well for us and even a basic autoencoder (2 layer autoencoder designed for MNIST data) worked really well at clustering several different fonts of letters. Even so, since the task is completely unique, we had no intuition regarding which autoencoder setup to use or how deep it will be required to be to learn a representation for this particular class of icons and fonts. It is still a challenge and we intend to evaluate results on several different architectures.</p>

<p>This project is still ongoing and there are engineering challenges for designing a good generative model for generating new images which can be discerned as both clipart and alphabet.</p>

<br /><br />
<!-- Results -->
<h2>Experiments and Results</h2>
<h4>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why?</h4>
We evaluated our autoencoder by visualizing clusters (trained on alphabet data only). We evaluated our final autoencoder trained on both alphabet and cliart data through qualitative results. We were successful in being able to select the best icons in the theme set. Some results are shown below. While autoencoder based results are decent, just looking at the cliparts is not enough to detect the underlying alphabet. We are currently working on using the clipart-alphabet pairs for pix2pix. We are also looking into GlyphNet wherein conditional GANs are trained specifically for learning font styles. Our work on generation is still ongoing and we plan to use crowd-sourcing for evaluation.

<br /><br />

<!-- Clustering scatterplots -->
<div class="row">
  <div class="column">
    <img src="../assets/img/scatter.png" alt="" style="width:100%" />
  </div>
  <div class="column">
    <img src="../assets/img/la_lb_ua_ub.png" alt="" style="width:100%" />
  </div>
  <div class="column">
    <img src="../assets/img/uo_uq_ue_uf.png" alt="" style="width:100%" />
  </div>
</div>
</div>

<p> The intermediate representations are reduced in dimensionality using TSNE and then clusters are plotted based on the alphabet labels for font images. The results are in accordance with what is expected. For example, in the third plot we expect uppercase O and uppercase Q to be similar looking and hence be in nearby clusters. Similarly we expect uppercase E and uppercase F to be close. Visually, we can see clear differences between O and Q vs E and F, and hence expect the distance between these 2 sets of clusters to be large. This is evident from the clusters.</p>

<br /><br />

<!-- Main Results Figure -->
<table style="width:100%">
  <tr>
    <th>Results</th>
    <th>Matched Alphabets</th>
    <th>Word</th>
    <th>Theme</th>
  </tr>
  <tr>
    <td><img style="height: 150px; width: 1000px;" alt="" src="../assets/img/always_harry_potter.png" /></td>
    <td><img style="height: 120px; width: 850px;" alt="" src="../assets/img/always_text.png" /></td>
    <td>Always</td>
    <td>Harry Potter</td>
  </tr>
  <tr>
    <td><img style="height: 150px; width: 1000px;" alt="" src="../assets/img/earth_environment.png" /></td>
    <td><img style="height: 120px; width: 850px;" alt="" src="../assets/img/earth_text.png" /></td>
    <td>Earth</td>
    <td>Environment</td>
  </tr>
  <tr>
    <td><img style="height: 150px; width: 1000px;" alt="" src="../assets/img/fail_education.png" /></td>
    <td><img style="height: 120px; width: 850px;" alt="" src="../assets/img/fail_text.png" /></td>
    <td>FAIL</td>
    <td>Education</td>
  </tr>
  <tr>
    <td><img style="height: 150px; width: 1000px;" alt="" src="../assets/img/taj_indian.png" /></td>
    <td><img style="height: 120px; width: 850px;" alt="" src="../assets/img/taj_text.png" /></td>
    <td>TAJ</td>
    <td>Indian</td>
  </tr>
</table>

<p><b>NOTE :</b>The model is being trained on ~40,000 Noun Project cliparts (randomly scraped from the website) and ~40,000 alphabets in ~770 different fonts (uppercase and lowercase). At test time, theme-based cliparts scraped from Noun Project and 10 specific fonts of alphabets are fed into the trained autoencoder to obtain a shared learned representation, on which cosine distance is applied to find the best matches. This is why the matched alphabets are not all of the same font as the font with least distance has been selected for each letter.</p>

  <hr />
  <footer>
  <p>© Purva Tendulkar</p>
  </footer>
</div>

<br /><br />

</body></html>


</article>

    


    <footer role="contentinfo">
  <hr/>
  
  <p><small class="copyright">© 2018. Purva Tendulkar.</small></p>
  
  <hr class="sr-only"/>
</footer>

  </main>
  <hy-drawer>
  <header id="_sidebar" class="sidebar" role="banner">
    
    <div class="sidebar-bg sidebar-overlay" style="background-color:#4fb1ba;background-image:url(assets/img/sidebar-bg.jpg)"></div>

    <div class="sidebar-sticky">
      <div class="sidebar-about">
        <h2 class="h1"><a href="/">Purva Tendulkar</a></h2>
        
        
          <p class="">
            MS CS Student at Georgia Tech

          </p>
        
      </div>

      <nav class="sidebar-nav heading" role="navigation">
        <span class="sr-only">Navigation:</span>
<ul>
  
  
  
  
    
      <li>
        <a
          id="_navigation"
          href="/tag/blogs/"
          class="sidebar-nav-item"
          
          >
          Blog
        </a>
      </li>
    
  
    
      <li>
        <a
          
          href="/tag/projects/"
          class="sidebar-nav-item"
          
          >
          Projects
        </a>
      </li>
    
  
    
      <li>
        <a
          
          href="/about/"
          class="sidebar-nav-item active"
          
          >
          Research
        </a>
      </li>
    
  
    
      <li>
        <a
          
          href="/details/"
          class="sidebar-nav-item"
          
          >
          CV
        </a>
      </li>
    
  
</ul>

      </nav>

      

      <div class="sidebar-social">
        <span class="sr-only">Social:</span>
<ul>
  
    
    
  

  

  
    













<li>
  <a href="https://github.com/purvaten" title="GitHub" class="no-mark-external">
    <span class="icon-github"></span>
    <span class="sr-only">GitHub</span>
  </a>
</li>

  
    













<li>
  <a href="https://www.linkedin.com/in/purva-tendulkar-774b48151/" title="LinkedIn" class="no-mark-external">
    <span class="icon-linkedin2"></span>
    <span class="sr-only">LinkedIn</span>
  </a>
</li>

  
    













<li>
  <a href="mailto:<purva.tendulkar@gmail.com>" title="Email" class="no-mark-external">
    <span class="icon-mail"></span>
    <span class="sr-only">Email</span>
  </a>
</li>

  
</ul>

      </div>
    </div>
  </header>
</hy-drawer>

</hy-push-state>


  
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-122476619-1', 'auto');
    ga('send', 'pageview');
    loadJSDeferred('https://www.google-analytics.com/analytics.js');
  </script>
  

  <!--[if gt IE 9]><!---->
  
  <script>loadJSDeferred('/assets/js/hydejack.js?v=7.0.0');</script>

  <!-- <script>
  function detectCFScript() {
    var cfScript = Array.prototype.find.call(document.scripts, function(s) {
      return s !== document.currentScript && s.textContent.indexOf('__cf_email__') > -1;
    });

    if (cfScript)
      this.addEventListener('hy-push-state-load', new Function(cfScript.textContent));

    this.removeEventListener('hy-push-state-init', detectCFScript);
  }

  document
    .getElementsByTagName('hy-push-state')[0]
    .addEventListener('hy-push-state-init', detectCFScript);
</script> -->


  <!--<![endif]-->



  
<hr class="sr-only"/>
<h2 class="sr-only">Templates (for web app):</h2>

<template id="_animation-template">
  <div class="animation-main fixed-top">
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

<template id="_loading-template">
  <div class="loading">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

<template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

<template id="_back-template">
  <a id="_back" class="back nav-btn no-hover">
    <span class="sr-only">Back</span>
    <span class="icon-arrow-left2"></span>
  </a>
</template>

</body>
</html>
